{
  "metadata": {
    "language_info": {
      "codemirror_mode": {
        "name": "python",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8"
    },
    "kernelspec": {
      "name": "python",
      "display_name": "Python (Pyodide)",
      "language": "python"
    }
  },
  "nbformat_minor": 4,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": "<p style=\"text-align:center\">\n    <a href=\"https://skills.network/?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMDeveloperSkillsNetworkML0101ENSkillsNetwork20718538-2022-01-01\" target=\"_blank\">\n    <img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/assets/logos/SN_web_lightmode.png\" width=\"200\" alt=\"Skills Network Logo\">\n    </a>\n</p>\n\n# K-Means Clustering\n\nEstimated time needed: **25** minutes\n\n## Objectives\n\nAfter completing this lab you will be able to:\n\n*   Use scikit-learn's K-Means Clustering to cluster data\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "## Introduction\n\nThere are many models for **clustering** out there. In this notebook, we will be presenting the model that is considered one of the simplest models amongst them. Despite its simplicity, the **K-means** is vastly used for clustering in many data science applications, it is especially useful if you need to quickly discover insights from **unlabeled data**. In this notebook, you will learn how to use k-Means for customer segmentation.\n\nSome real-world applications of k-means:\n\n*   Customer segmentation\n*   Understand what the visitors of a website are trying to accomplish\n*   Pattern recognition\n*   Machine learning\n*   Data compression\n\nIn this notebook we practice k-means clustering with 2 examples:\n\n*   k-means on a random generated dataset\n*   Using k-means for customer segmentation\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "<h1>Table of contents</h1>\n\n<div class=\"alert alert-block alert-info\" style=\"margin-top: 20px\">\n    <ul>\n        <li><a href=\"https://#random_generated_dataset\">k-Means on a randomly generated dataset</a></li>\n            <ol>\n                <li><a href=\"https://#setting_up_K_means\">Setting up K-Means</a></li>\n                <li><a href=\"https://#creating_visual_plot\">Creating the Visual Plot</a></li>\n            </ol>\n        <p></p>\n        <li><a href=\"https://#customer_segmentation_K_means\">Customer Segmentation with K-Means</a></li>\n            <ol>\n                <li><a href=\"https://#pre_processing\">Pre-processing</a></li>\n                <li><a href=\"https://#modeling\">Modeling</a></li>\n                <li><a href=\"https://#insights\">Insights</a></li>\n            </ol>\n    </ul>\n</div>\n<br>\n<hr>\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "### Import the Libraries\n\nLet's first import the required libraries.\nAlso run <b> %matplotlib inline </b> since we will be plotting in this section.\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "#you are running the lab in your  browser, so we will install the libraries using ``piplite``\nimport piplite\nawait piplite.install(['pandas'])\nawait piplite.install(['matplotlib'])\nawait piplite.install(['scipy'])\nawait piplite.install(['seaborn'])\n",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "import random \nimport numpy as np \nimport matplotlib.pyplot as plt \nfrom sklearn.cluster import KMeans \nfrom sklearn.datasets import make_blobs \n%matplotlib inline",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "def warn(*args, **kwargs):\n    pass\nimport warnings\nwarnings.warn = warn\nwarnings.filterwarnings('ignore')",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "### Download the Data\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "from pyodide.http import pyfetch\n\nasync def download(url, filename):\n    response = await pyfetch(url)\n    if response.status == 200:\n        with open(filename, \"wb\") as f:\n            f.write(await response.bytes())",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "<h1 id=\"random_generated_dataset\">k-Means on a randomly generated dataset</h1>\n\nLet's create our own dataset for this lab!\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "First we need to set a random seed. Use <b>numpy's random.seed()</b> function, where the seed will be set to <b>0</b>.\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "np.random.seed(0)",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "Next we will be making <i> random clusters </i> of points by using the <b> make_blobs </b> class. The <b> make_blobs </b> class can take in many inputs, but we will be using these specific ones. <br> <br> <b> <u> Input </u> </b>\n\n<ul>\n    <li> <b>n_samples</b>: The total number of points equally divided among clusters. </li>\n    <ul> <li> Value will be: 5000 </li> </ul>\n    <li> <b>centers</b>: The number of centers to generate, or the fixed center locations. </li>\n    <ul> <li> Value will be: [[4, 4], [-2, -1], [2, -3],[1,1]] </li> </ul>\n    <li> <b>cluster_std</b>: The standard deviation of the clusters. </li>\n    <ul> <li> Value will be: 0.9 </li> </ul>\n</ul>\n<br>\n<b> <u> Output </u> </b>\n<ul>\n    <li> <b>X</b>: Array of shape [n_samples, n_features]. (Feature Matrix)</li>\n    <ul> <li> The generated samples. </li> </ul> \n    <li> <b>y</b>: Array of shape [n_samples]. (Response Vector)</li>\n    <ul> <li> The integer labels for cluster membership of each sample. </li> </ul>\n</ul>\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "X, y = make_blobs(n_samples=5000, centers=[[4,4], [-2, -1], [2, -3], [1, 1]], cluster_std=0.9)",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "Display the scatter plot of the randomly generated data.\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "plt.scatter(X[:, 0], X[:, 1], marker='.')",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "<h2 id=\"setting_up_K_means\">Setting up K-Means</h2>\nNow that we have our random data, let's set up our K-Means Clustering.\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "The KMeans class has many parameters that can be used, but we will be using these three:\n\n<ul>\n    <li> <b>init</b>: Initialization method of the centroids. </li>\n    <ul>\n        <li> Value will be: \"k-means++\" </li>\n        <li> k-means++: Selects initial cluster centers for k-mean clustering in a smart way to speed up convergence.</li>\n    </ul>\n    <li> <b>n_clusters</b>: The number of clusters to form as well as the number of centroids to generate. </li>\n    <ul> <li> Value will be: 4 (since we have 4 centers)</li> </ul>\n    <li> <b>n_init</b>: Number of time the k-means algorithm will be run with different centroid seeds. The final results will be the best output of n_init consecutive runs in terms of inertia. </li>\n    <ul> <li> Value will be: 12 </li> </ul>\n</ul>\n\nInitialize KMeans with these parameters, where the output parameter is called <b>k_means</b>.\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "k_means = KMeans(init = \"k-means++\", n_clusters = 4, n_init = 12)",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "Now let's fit the KMeans model with the feature matrix we created above, <b> X </b>.\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "k_means.fit(X)",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "Now let's grab the labels for each point in the model using KMeans' <b> .labels\\_ </b> attribute and save it as <b> k_means_labels </b>.\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "k_means_labels = k_means.labels_\nk_means_labels",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "We will also get the coordinates of the cluster centers using KMeans' <b> .cluster_centers\\_ </b> and save it as <b> k_means_cluster_centers </b>.\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "k_means_cluster_centers = k_means.cluster_centers_\nk_means_cluster_centers",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "<h2 id=\"creating_visual_plot\">Creating the Visual Plot</h2>\n\nSo now that we have the random data generated and the KMeans model initialized, let's plot them and see what it looks like!\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "Please read through the code and comments to understand how to plot the model.\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "# Initialize the plot with the specified dimensions.\nfig = plt.figure(figsize=(6, 4))\n\n# Colors uses a color map, which will produce an array of colors based on\n# the number of labels there are. We use set(k_means_labels) to get the\n# unique labels.\ncolors = plt.cm.Spectral(np.linspace(0, 1, len(set(k_means_labels))))\n\n# Create a plot\nax = fig.add_subplot(1, 1, 1)\n\n# For loop that plots the data points and centroids.\n# k will range from 0-3, which will match the possible clusters that each\n# data point is in.\nfor k, col in zip(range(len([[4,4], [-2, -1], [2, -3], [1, 1]])), colors):\n\n    # Create a list of all data points, where the data points that are \n    # in the cluster (ex. cluster 0) are labeled as true, else they are\n    # labeled as false.\n    my_members = (k_means_labels == k)\n    \n    # Define the centroid, or cluster center.\n    cluster_center = k_means_cluster_centers[k]\n    \n    # Plots the datapoints with color col.\n    ax.plot(X[my_members, 0], X[my_members, 1], 'w', markerfacecolor=col, marker='.')\n    \n    # Plots the centroids with specified color, but with a darker outline\n    ax.plot(cluster_center[0], cluster_center[1], 'o', markerfacecolor=col,  markeredgecolor='k', markersize=6)\n\n# Title of the plot\nax.set_title('KMeans')\n\n# Remove x-axis ticks\nax.set_xticks(())\n\n# Remove y-axis ticks\nax.set_yticks(())\n\n# Show the plot\nplt.show()\n",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "## Practice\n\nTry to cluster the above dataset into 3 clusters.\\\nNotice: do not generate the data again, use the same dataset as above.\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "# write your code here\n",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "<details><summary>Click here for the solution</summary>\n\n```python\nk_means3 = KMeans(init = \"k-means++\", n_clusters = 3, n_init = 12)\nk_means3.fit(X)\nfig = plt.figure(figsize=(6, 4))\ncolors = plt.cm.Spectral(np.linspace(0, 1, len(set(k_means3.labels_))))\nax = fig.add_subplot(1, 1, 1)\nfor k, col in zip(range(len(k_means3.cluster_centers_)), colors):\n    my_members = (k_means3.labels_ == k)\n    cluster_center = k_means3.cluster_centers_[k]\n    ax.plot(X[my_members, 0], X[my_members, 1], 'w', markerfacecolor=col, marker='.')\n    ax.plot(cluster_center[0], cluster_center[1], 'o', markerfacecolor=col,  markeredgecolor='k', markersize=6)\nplt.show()\n\n```\n\n</details>\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "<h1 id=\"customer_segmentation_K_means\">Customer Segmentation with K-Means</h1>\n\nImagine that you have a customer dataset, and you need to apply customer segmentation on this historical data.\nCustomer segmentation is the practice of partitioning a customer base into groups of individuals that have similar characteristics. It is a significant strategy as a business can target these specific groups of customers and effectively allocate marketing resources. For example, one group might contain customers who are high-profit and low-risk, that is, more likely to purchase products, or subscribe for a service. A business task is to retain those customers. Another group might include customers from non-profit organizations and so on.\n\nLet's download the dataset from IBM Object Storage.  **Did you know?** When it comes to Machine Learning, you will likely be working with large datasets. As a business, where can you host your data? IBM is offering a unique opportunity for businesses, with 10 Tb of IBM Cloud Object Storage: [Sign up now for free](http://cocl.us/ML0101EN-IBM-Offer-CC)\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "path='https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-ML0101EN-SkillsNetwork/labs/Module%204/data/Cust_Segmentation.csv'",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "### Load Data From CSV File\n\nBefore you can work with the data, you must use the URL to get the Cust_Segmentation.csv.\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "await download(path, \"Cust_Segmentation.csv\")\nfilename =\"Cust_Segmentation.csv\"",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "we create a pandas dataframe\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "import pandas as pd\ncust_df = pd.read_csv(\"Cust_Segmentation.csv\")\ncust_df.head()",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "<h2 id=\"pre_processing\">Pre-processing</h2\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "As you can see, **Address** in this dataset is a categorical variable. The k-means algorithm isn't directly applicable to categorical variables because the Euclidean distance function isn't really meaningful for discrete variables. So, let's drop this feature and run clustering.\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "df = cust_df.drop('Address', axis=1)\ndf.head()",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "#### Normalizing over the standard deviation\n\nNow let's normalize the dataset. But why do we need normalization in the first place? Normalization is a statistical method that helps mathematical-based algorithms to interpret features with different magnitudes and distributions equally. We use **StandardScaler()** to normalize our dataset.\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "from sklearn.preprocessing import StandardScaler\nX = df.values[:,1:]\nX = np.nan_to_num(X)\nClus_dataSet = StandardScaler().fit_transform(X)\nClus_dataSet",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "<h2 id=\"modeling\">Modeling</h2>\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "In our example (if we didn't have access to the k-means algorithm), it would be the same as guessing that each customer group would have certain age, income, education, etc, with multiple tests and experiments. However, using the K-means clustering we can do all this process much easier.\n\nLet's apply k-means on our dataset, and take a look at cluster labels.\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "clusterNum = 3\nk_means = KMeans(init = \"k-means++\", n_clusters = clusterNum, n_init = 12)\nk_means.fit(X)\nlabels = k_means.labels_\nprint(labels)",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "<h2 id=\"insights\">Insights</h2>\n\nWe assign the labels to each row in the dataframe.\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "df[\"Clus_km\"] = labels\ndf.head(5)",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "We can easily check the centroid values by averaging the features in each cluster.\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "df.groupby('Clus_km').mean()",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "Now, let's look at the distribution of customers based on their age and income:\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "area = np.pi * ( X[:, 1])**2  \nplt.scatter(X[:, 0], X[:, 3], s=area, c=labels.astype(float), alpha=0.5)\nplt.xlabel('Age', fontsize=18)\nplt.ylabel('Income', fontsize=16)\n\nplt.show()\n",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "from mpl_toolkits.mplot3d import Axes3D \nfig = plt.figure(1, figsize=(8, 6))\nplt.clf()\nax = Axes3D(fig, rect=[0, 0, .95, 1], elev=48, azim=134)\n\nplt.cla()\n# plt.ylabel('Age', fontsize=18)\n# plt.xlabel('Income', fontsize=16)\n# plt.zlabel('Education', fontsize=16)\nax.set_xlabel('Education')\nax.set_ylabel('Age')\nax.set_zlabel('Income')\n\nax.scatter(X[:, 1], X[:, 0], X[:, 3], c= labels.astype(float))\n\n",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "k-means will partition your customers into mutually exclusive groups, for example, into 3 clusters. The customers in each cluster are similar to each other demographically.\nNow we can create a profile for each group, considering the common characteristics of each cluster.\nFor example, the 3 clusters can be:\n\n*   AFFLUENT, EDUCATED AND OLD AGED\n*   MIDDLE AGED AND MIDDLE INCOME\n*   YOUNG AND LOW INCOME\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "<h2>Want to learn more?</h2>\n\nIBM SPSS Modeler is a comprehensive analytics platform that has many machine learning algorithms. It has been designed to bring predictive intelligence to decisions made by individuals, by groups, by systems – by your enterprise as a whole. A free trial is available through this course, available here: <a href=\"https://www.ibm.com/analytics/spss-statistics-software?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMDeveloperSkillsNetworkML0101ENSkillsNetwork20718538-2021-01-01\">SPSS Modeler</a>\n\nAlso, you can use Watson Studio to run these notebooks faster with bigger datasets. Watson Studio is IBM's leading cloud solution for data scientists, built by data scientists. With Jupyter notebooks, RStudio, Apache Spark and popular libraries pre-packaged in the cloud, Watson Studio enables data scientists to collaborate on their projects without having to install anything. Join the fast-growing community of Watson Studio users today with a free account at <a href=\"https://www.ibm.com/cloud/watson-studio?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMDeveloperSkillsNetworkML0101ENSkillsNetwork20718538-2021-01-01\">Watson Studio</a>\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "### Thank you for completing this lab!\n\n## Author\n\nSaeed Aghabozorgi\n\n### Other Contributors\n\n<a href=\"https://www.linkedin.com/in/joseph-s-50398b136/?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMDeveloperSkillsNetworkML0101ENSkillsNetwork20718538-2021-01-01\" target=\"_blank\">Joseph Santarcangelo</a>\n\n## Change Log\n\n| Date (YYYY-MM-DD) | Version | Changed By | Change Description                 |\n| ----------------- | ------- | ---------- | ---------------------------------- |\n| 2020-11-03        | 2.1     | Lakshmi    | Updated URL of csv                 |\n| 2020-08-27        | 2.0     | Lavanya    | Moved lab to course repo in GitLab |\n|                   |         |            |                                    |\n|                   |         |            |                                    |\n\n## <h3 align=\"center\"> © IBM Corporation 2020. All rights reserved. <h3/>\n",
      "metadata": {}
    }
  ]
}